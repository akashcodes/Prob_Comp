\documentclass[12pt]{article}
\usepackage[ansinew]{inputenc} % ASCII (Western CP)
\usepackage{graphicx}
\usepackage{color}
\usepackage[colorlinks]{hyperref}
\usepackage{geometry}
\usepackage{amsmath}
\geometry{left=2.5cm,right=2.5cm,top=2.5cm,bottom=2.5cm}

\title{Probability and Computing - HW2}
\author{Pang Liang\\ Student No. 201418013229033}

\begin{document}
\maketitle

\section{Problem1}
Prove the following extensions of the Chernoff bound. Let $X=\sum_{i=1}^{n} X_i$, where the $X_i$ are independent 0-1 random variables. Let $\mu = E[X]$. Choose any $\mu_L$ and $\mu_H$ such that $\mu_L \le \mu \le \mu_H$. Then, for any $\delta > 0$, $Pr(X \ge (1+\delta) \mu_H) \le (\frac{e^\delta}{(1+\delta)^{(1+\delta)}}) \mu_H$.
Similarly, for any $0 < \delta < 1$, $Pr(X \le (1-\delta) \mu_L) \le (\frac{e^{-\delta}}{(1-\delta)^{(1-\delta)}}) \mu_L$.\\

Apply Markov's inequality, for any $t>0$ we have
\begin{equation}
    \begin{split}
    Pr(X \ge (1+\delta) \mu_H) &= Pr(e^{tX} \ge e^{t(1+\delta)\mu_H})\\
    &\le \frac{E[e^{tX}]}{e^{t(1+\delta)\mu_H}} \\
    &\le \frac{e^{(e^t-1)\mu}}{e^{t(1+\delta)\mu_H}} \\
    &\le \frac{e^{(e^t-1)\mu_H}}{e^{t(1+\delta)\mu_H}}
    \end{split}
\end{equation}

For any $\delta>0$, we can set $t=ln(1+\delta)$ then
\begin{equation}
    \begin{split}
    Pr(X \ge (1+\delta) \mu_H) &\le \frac{e^{(e^t-1)\mu_H}}{e^{t(1+\delta)\mu_H}} \\
    &= (\frac{e^\delta}{(1+\delta)^{(1+\delta)}}) \mu_H
    \end{split}
\end{equation}

Apply Markov's inequality, for any $t<0$ we have
\begin{equation}
    \begin{split}
    Pr(X \le (1-\delta) \mu_L) &= Pr(e^{tX} \ge e^{t(1-\delta)\mu_L})\\
    &\le \frac{E[e^{tX}]}{e^{t(1-\delta)\mu_L}} \\
    &\le \frac{e^{(e^t-1)\mu}}{e^{t(1-\delta)\mu_L}} \\
    &\le \frac{e^{(e^t-1)\mu_L}}{e^{t(1-\delta)\mu_L}}
    \end{split}
\end{equation}
For any $0<\delta<1$, we can set $t=ln(1-\delta)<0$ then
\begin{equation}
    \begin{split}
    Pr(X \le (1-\delta) \mu_L) &\le \frac{e^{(e^t-1)\mu_L}}{e^{t(1-\delta)\mu_L}} \\
    &= (\frac{e^{-\delta}}{(1-\delta)^{(1-\delta)}}) \mu_L
    \end{split}
\end{equation}

\section{Problem2}
Consider a collection $X_1, \cdots X_n$ of n independent integers chosen uniformly from the set $\{0,1,2\}$. Let $X=\sum_{i=1}^{n}X_i$ and $0 < \delta < 1$. Derive a Chernoff bound for $Pr(X \le (1-\delta)n)$.\\

First we need to calculate the generating function of $X_i$, $M_{X_i}(t)$
\begin{equation}
    \begin{split}
    M_{X_i}(t) &= E[e^{tX_i}] \\
    &= \frac{1}{3} (1+e^t+e^{2t})
    \end{split}
\end{equation}

Then we take the product of the n generating functions to obtain
\begin{equation}
    \begin{split}
    M_X(t) &= \prod_{i=1}^{n}M_{X_i}(t) \\
    &= \prod_{i=1}{n} \frac{1}{3} (1+e^t+e^{2t})\\
    &= (\frac{1}{3} (1+e^t+e^{2t}))^n
    \end{split}
\end{equation}

Apply Markov's inequality, for any $t<0$ we have

\begin{equation}
    \begin{split}
    Pr(X \le (1-\delta)n) &= Pr(e^{tX} \ge e^{t(1-\delta)n})\\
    &\le \frac{E[e^{tX}]}{e^{t(1-\delta)n}} \\
    &= \frac{[(1+e^t+e^{2t})/3]^n}{e^{t(1-\delta)n}}
    \end{split}
\end{equation}

let $t=ln\delta<0$
\begin{equation}
    \begin{split}
    Pr(X \le (1-\delta)n) &\le \frac{[(1+e^t+e^{2t})/3]^n}{e^{t(1-\delta)n}} \\
    &= [\frac{(1+\delta+2\delta)}{3\delta^{(1-\delta)}}]^n
    \end{split}
\end{equation}

\section{Problem3}
Let $X_1, \cdots X_n$ be independent Poisson trials such that $Pr(X_i = 1) = p_i$ and let $a_1, \cdots a_n$ be real numbers in $[0, 1]$. let $X = \sum_{i=1}^{n} a_iX_i$ and $\mu = E[X]$. Then the following Chernoff bound holds: for any $\delta > 0$, $Pr(X \ge (1+\delta) \mu) \le (\frac{e^\delta}{(1+\delta)^{(1+\delta)}})^\mu$. Also prove a similar bound for the probability $Pr(X \le (1-\delta)\mu)$ for any $0 < \delta < 1$.\\

First we can see that $\mu=E[X]=\sum_{i=1}^{n} a_ip_i$, and use this to calculate $M_X(t)$. We can see that $M_{X_i}(t) = 1+p_i(e_t-1)$, so
\begin{equation}
    \begin{split}
    E(e^{tX}) = M_X(t) &= \prod_{i=1}^{n} (a_i + a_i p_i (e^t-1)) \\
    &\le \prod_{i=1}^{n} (1 + a_i p_i (e^t-1)) \\
    &\le \prod_{i=1}^{n} e^{a_i p_i (e^t-1)} \\
    &= \exp{\sum_{i=1}^{n} a_i p_i (e^t-1)} \\
    &= e^{(e^t-1)\mu}
    \end{split}
\end{equation}

Then we get the same the product of the n generating functions as the independent Poisson trials has. So we get the same Chernoff bound.
That is to say
$Pr(X \ge (1+\delta) \mu) \le (\frac{e^\delta}{(1+\delta)^{(1+\delta)}})^\mu$ for any $\delta>0$ and  $Pr(X \le (1-\delta)\mu)\le (\frac{e^{-\delta}}{(1-\delta)^{(1-\delta)}})^\mu$ for any $0 < \delta < 1$.


\section{Problem4}
Recall that a function $f$ is said to be convex if, for any $x_1, x_2$ and for $0 \le \lambda \le 1$, $f(\lambda x_1 + (1-\lambda) x_2) \le \lambda f(x_1)+ (1-\lambda) f(x_2)$.
\begin{itemize}
    \item Let $Z$ be a random variable that takes on a finite set of values in $[0, 1]$, and let $p = E[Z]$. Define the Bernoulli random variable $X$ by $Pr(X = 1) = p$ and $Pr(X = 0) = 1-p$. Show that $E[f(Z)] \le E[f(X)]$ for any convex function $f$.
    \item Use the fact that $f(x) = e^{tx}$ is convex for any fixed $t \ge 0$ to obtain a Chernoff-like bound for $Z$.\\
\end{itemize}

\begin{itemize}
    \item 
    First we have
    \begin{equation}
        \begin{split}
        \int_{0}^{1} p_z dz &= 1\\
        \int_{0}^{1} z p_z dz &= p \\
        \end{split}
    \end{equation}
    
    Then use the convexity of $f$
    \begin{equation}
        \begin{split}
        f(z) &= f(0*(1-z) + 1*z) \le f(0)*(1-z) + f(1)*z \\
        &= (f(1)-f(0))*z + f(0)
        \end{split}
    \end{equation}
    
    Now we evaluate $E[f(X)]$
    \begin{equation}
        E[f(X)]=f(0)*(1-p) + f(1)*p
    \end{equation}
    
    And evaluate $E[f(Z)]$
    \begin{equation}
        \begin{split}
        E[f(Z)] &= \int_{0}^{1} f(z) p_z dz \\
        &\le \int_{0}^{1} (f(1)-f(0))*zp_z + f(0)p_z dz \\
        &= f(0)*(1-p)+f(1)*p=E[f(X)]
        \end{split}
    \end{equation}
    
    So we have $E[f(Z)] \le E[f(X)]$.
    
    \item
    First we have $E[e^{tX}] = (1-p) + pe^t$.
    Apply Markov's inequality, for any $t>0$ we have
    \begin{equation}
        \begin{split}
        Pr(Z \ge a) &= Pr(e^{tZ} \ge e^{ta}) \le \frac{E(e^{tZ})}{e^{ta}} \\
        &\le \frac{E(e^{tX})}{e^{ta}} = \frac{pe^t-p+1}{e^{ta}}
        \end{split}
    \end{equation}
    So we have $Pr(Z \ge a) \le \frac{pe^t-p+1}{e^{ta}}$ for any $t>0$.
    
\end{itemize}

\section{Problem5}
Do Bernoulli experiment for 20 trials, using a new 1-Yuan coin. Record the result in a string $s_1s_2 \cdots s_i \cdots s_{20}$, where $s_i$ is 1 if the $i^{th}$ trial gets Head, and otherwise is 0.\\

0010111001 0001000010
\end{document}
